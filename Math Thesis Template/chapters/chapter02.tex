There exists many different graph properties that can be applied according to specific graph types. Hence we will focus on properties that will be applied to connected weighted graphs to provide a collection of views targeted for the same layout structure and to enable a wider selection of properties. Hence, unless stated otherwise, the properties described in this chapter will be of the form of connected weighted graphs.

\section{Trophic Coherence}
Firstly the graph property of \emph{trophic coherence}\cite{johnson2014trophic}, this property determines the stability of the graph and provides trophic levels to the graph and it's individual vertices. Trophic levels are taken from ecology and applied to graphs to generate a height based format for the vertices of a graph. Thus, for a graph $G =(V,E)$ (can be directed), we have $V$ which is the set of all vertices in $G$ and $E$ which is the set of all the edges within $G$. The graph can be represented with an adjacency matrix $A$ where $a_{ij}$ denotes the elements within the matrix. The standard trophic level definition on vertex level uses the in degree and the out degree of the vertex $v_i$ given by Equation \ref{eq:inoutt}.

\begin{equation} \label{eq:inoutt}
k_i^{\text{in}} = \sum_ja_{ij} , \qquad \qquad k_i^{\text{out}} = \sum_ja_{ji} 
\end{equation}

So, the standard trophic levels for vertices $v_i \in V$ is formulated as:

\begin{equation}
t_i = 1 + \frac{1}{k_i^{\text{in}}}\sum_ja_{ij}t_j
\end{equation}

By ecological convention, $t_i = 1$, if the vertex $v_i$ is \emph{basal}. A vertex is known to be basal if it has no edged directed to it, i.e. $k_i^{\text{in}} = 0$. The trophic level equation can also simply be written in matrix form by \ref{eq:mtl} with $\bold{z}$ be defined as $z_i = \text{max}(k_i^{\text{in}},1)$ and $\Delta = \text{diag}(\bold{z}) - A$.

\begin{equation} \label{eq:mtl}
\Delta\bold{t} = \bold{z} 
\end{equation}

All vertices will receive a trophic level if and only if the laplacian $\Delta$ is invertible as the row sum of elements in $\Delta$ for a vertex that isn't basal is zero. If there are no basal vertices in the graph then $\Delta$ will be equal to zero and thus be singular (i.e. no inverse). This is discussed by Samuel Johnson \cite{johnson2020digraphs} in the investigation of stability and such dynamical features within graphs. So for the standard trophic levels equation to work for the entire graph, there must exist at least one basal vertex meaning that this is a limitation to the definition of trophic levels.

\subsection{Inclusion of weights and equation improvement}
In a weighted graph, edges carry a weight between a vertex $u$ to a vertex $v$. Weighted matrix $W$ are used as a representation of the entire graph along with incorporating the direction of each edge and if there exists self loops. The elements of the weighted matrix are $w_{uv}$. If the graph isn't weighted then the edge is valued as 1 if the edge exists and 0 otherwise, i.e. the adjacency matrix of G. The total weight (also known as the strength) for each vertex is defined by the weights into a vertex $u$ and the weights out of vertex $u$, which is shown by $s_v$ in Equation \ref{eq:strength}. This is essentially the same as the in and out degrees of Equation \ref{eq:inoutt} mentioned previously but instead of ones and zeros, the weight values are taken into account. The imbalance of the vertex $u$ is defined by the weights in of a vertex minus the weights out of the vertex shown by $i_v$ in Equation \ref{eq:imb}.

\begin{align}
s_v &= \sum(w_{uv}) + \sum(w_{vu}) \label{eq:strength} \\
i_v &= \sum(w_{uv}) - \sum(w_{vu}) \label{eq:imb}
\end{align}

Vectors $\bold{s}$ and $\bold{i}$ holds all the values of the strength and imbalance for all vertices respectively. We let $\bold{h}$ be a vector, then the graph Laplacian operator in matrix form is defined by Equation \ref{eq:delt}.  

\begin{equation} \label{eq:delt}
\Delta = \text{diag}(u) - W - W^T
\end{equation}

Therefore to get the trophic levels for each vertex with consideration for the additional weights, we solve the system of equations for vector $\bold{h}$ as shown by Equation \ref{eq:h}.

\begin{equation} \label{eq:h}
\Delta \bold{h} = \bold{v} 
\end{equation}

The values within this vector $h$ corresponds to the trophic levels for the relative vertices. The values are used to illustrate the various trophic levels within a graph to give a hierarchical format visualisation. Trophic levels aren't unique solutions due to the fact that an arbitrary constant can be added to each component of the graph if there are multiple components to generate new levels that would be correct. The benefit that this is that Equation \ref{eq:h} can use an arbitrary constant $c$ for a vertex in $\bold{h}$. If there are multiple components to the graph then a vertex in each component. A unique solution can be found this way in which the trophic level values can be shifted so that a better graphical display can be generated. For example, have the lowest level be zero. 

Trophic level values can also be used to equate the overall \emph{trophic incoherence} of the graph as a whole rather than just looking at the graph on a vertex level. By using the trophic levels from $\bold{h}$, the equation for the trophic incoherence is defined by R. S. MacKay, S. Johnson, B. Sansom\cite{johnson2020digraphs} as:

\begin{equation}
F_0=\frac{\sum_{uv}w_{uv}(h_v-h_u-1)^2}{\sum_{uv}w_{uv}}
\end{equation}

The possible shifting of the trophic levels doesn't affect the trophic incoherence hence it is independent. The incoherence is strictly ranged from zero to one. If $F_0 = 0$  then the graph is \emph{maximally coherent} as it would mean that all levels in the graph has a difference of exactly one which means that the graph is perfectly separated into levels. Whereas if $F_0 = 1$ then the graph is \emph{maximally incoherent} and levels are harder to decipher. As $F_0$ measure the incoherence, by taking $1 - F_0$, this would instead measure the coherence of the graph as they're each others converses. 
\newline

In conclusion, trophic levels can be applied to weighted directed graph and any subcategories to achieve a hierarchical view of the graph. This eases the visualisation of many datasets and is used to decipher valuable information that may be of use. Through the combination of other graph properties which are described in this chapter, various combinations of these properties will yield different visualisations.


\section{Clustering Coefficient}
The \emph{transitivity} \cite{schank2005approximating} of a graph, also known as \emph{clustering}, is a property of a graph that measured the density of triangles within the graph, where three vertices are connected together. Used to quantify the graph's connectivity strength as it determines the fraction of triangles over the possible triangles that could be formed within the graph. Another perspective is that the coefficient quantifies the probability of a vertex $a$ having an edge to vertex $c$ if $ab$, $bc \in E(G)$. Thus, the \emph{clustering coefficient} determines how complete the graph is with a value of 1 meaning it is complete. There are two popular introductions of clustering coefficient, the \emph{local clustering} and the \emph{global clustering}. The global clustering coefficient essentially measures the completeness of the graph by measuring the number of exisitng triangles divided by the number of possible triangles in the graph. The local clustering coefficient measures the clustering coefficient for each vertex rather than the whole graph, the measurement is taken by the number of triangles that has a connection to the vertex over the number of triples centred on this vertex. In other words, the local value demonstrates how close the neighbours of this vertex is to being a complete graph (a \emph{clique}).

\subsection{Clustering for simple graphs}
To determine the values of the clustering coefficient for simple connected graphs that are unweighted and undirected, the global clustering coefficient is defined by equation \ref{eq:sgcc} where $\sum{T}$ denotes the number of triangles (closed triplets) and $\sum{\tau}$ denotes the number of connected triplets in the graph.
\begin{equation} \label{eq:sgcc}
C = \frac{3\text{(Number of total triangles)}}{\text{Number of total connected triples}} = \frac{\sum{T}}{\sum{\tau}}
\end{equation}
An alternative equation which was demonstrated by M.E.J. Newman \cite{Newman_2003} through the studies of complex networks in terms of social networks where the clustering coefficient determines the likelihood that a friend of your friend is also your friend. So, the alternative equation is written in the form of equation \ref{eq:sgccp} where $\sum{P_2}$ denotes the number of paths with length two within the graph.
\begin{equation} \label{eq:sgccp}
C = \frac{6\text{(Number of total triangles)}}{\text{Number of paths with length 2}} = \frac{\sum{T}}{\sum{P_2}}
\end{equation}

By considering the vertices of the graph, the local clustering coefficient can be defined to give such a value to each vertex $v\in V(G)$ and is given by the equation \ref{eq:slcc} where i is the index of the vertex. This definition is from \cite{Newman_2003} and proposed by Watts and Strogats \cite{Watts1998} where they analysed small world networks in relation to various real world systems by the use of clustering coefficients and random graphs to formulate certain similarities. Note that if the degree of a vertex is one then the coefficient can be determined as 0, otherwise the equation will lead to $0/0$.
\begin{equation} \label{eq:slcc}
C_i = \frac{\text{Number of triangles connected to $i$}}{\text{Number of triples centred on vertex $i$}}
\end{equation}

Another representation of the global clustering coefficient is to take the averages of all the local coefficients\cite{https://doi.org/10.48550/arxiv.1410.1997}. When the vertices have a degree of 0 or 1 then $C_i = 0$ so clustering coefficient is defined by equation \ref{eq:sglcc}.
\begin{equation} \label{eq:sglcc}
C = \frac{1}{n}\sum_i{C_i}
\end{equation}
Later the clustering coefficients will be used as assistance to model graphs generated off of a dataset. However to provide more accurate values, then weights and directions would need to be taken into account. Thus, the definitions of clustering coefficients must be developed further.

\subsection{Clustering for weighted graphs}
Now by considering graphs as before but weighted, the equations undergo changes. For the instance of weighted graphs, there are multiple different definitions of clustering coefficients, each with slight variation in values depending on the type of graph. This section will summarise a couple of the different definitions for weighted and directed graphs and further detail can be analysed from Tanguy and Anna Levina on weighted directed clustering \cite{PhysRevResearch.3.043124}. In this paper, four different definitions are reviewed which are the Barrat definition, Onnela's definition, Zhang \& Horvath and their own continuous definition for weighted graphs. Zhang \& Horvath\cite{ZhangHorvath+2005} have used their definition of weighted clustering coefficients to analyse gene co-expression networks to review their functionality. Additionally, by soft or hard thresholding, it enables them to determine relationships between the clustering coefficient and gene networks within biology.

A simple idea to associate the clustering coefficient with regards to the edge weights is to define a value $w$ that represents the value of the triplet. $w$ can be the summation of the triplet, the mean of the triplet or another suitable method depending on the purpose. Then equation \ref{eq:wcc} calculates the weighted clustering coefficient\cite{opsahl2009clustering} where T denote the triangles in the graph and $\tau$, the triples.
\begin{equation} \label{eq:wcc}
C = \frac{\text{Total of closed }w}{\text{Total of }w} = \frac{\sum_T{w}}{\sum_\tau{w}}
\end{equation}

Weights can be added trivially through this way, in which it won't affect the equations formalised beforehand. So now considering the addition of directions as well as weights which causes further complexities in the values of clustering coefficients due to the various number of different motifs used to describe the nature of the triangles. For instance, there are sixteen possible motifs for directed graphs of three vertices shown in Figure\ref{fig:3nodes}. However if we consider only connected triangles, they can be organised into four types of motif groups known as a cycles, Middleman, Fan-in and Fan-out as demonstrated in Figure \ref{fig:change} which are used in the study of higher order motifs and synaptic integration by Bojanek, Zhu and Maclean\cite{synaptic}. An interesting result used in this paper is the isomorphisms between the middleman, fan-in and fan-out motifs.

\begin{figure}[!htb]
\centering
\begin{subfigure}{.45\textwidth}
	\includegraphics[scale=0.8]{3nodes}
	\caption{All sixteen motifs of possible connections between three nodes and their directions shown on the edges. Ranges from zero edges to the maximum of six edges. Image sourced from Math Insight\cite{mathinsight}.}
	\label{fig:3nodes}
\end{subfigure}
\hfill
\begin{subfigure}{.45\textwidth}
	\includegraphics[scale=0.65]{change}
	\caption{The four named categories of motifs in which all directed connected triangles fall under. Each pair of motifs is listed as the corresponding types which are cycles, middleman, fan-in and fan-out. Image displaced from \cite{synapticimg}.}
	\label{fig:change}
\end{subfigure}
\end{figure}

Consideration of the edge's directions yields better accuaracy in the coefficient values. One of the versions mentioned in the paper \cite{PhysRevResearch.3.043124} was Fagios where he introduces the clustering coefficient to binary directed networks which are equivalent to simple directed connected graphs. Firstly the equation for the directed version without the consideration of weights is defined by the ratio of all directed triangles centred on a vertex $i \in V(G)$ and the number of all possible triangles that could be formed with vertex $i$, These are called $t_{i}$ and $T_{i}$ respectively. Before this equation, prior properties of the graph are necessary so that the equation can be easily formulated. Thus, consider a graph $G = (V, E)$ with its matrix representation as the adjacency matrix $A$ along with $V_1$ as the column vector, dimension $n$ of the graph, of only 1s. $A_i$ is the i-th row of the adjacency matrix. The in-degrees and out-degrees of a graph are the total number of edges going in or out of a vertex $i\in V(G)$ respectively, the total degree is the sum of the in and out degrees shown by equations $\ref{eq:idod}$.

\begin{align} \label{eq:idod}
\text{in}(d_i) &= \sum_{i\neq j}a_{ji} = (A^T)_i V_1 \\
\text{out}(d_i) &= \sum_{i\neq j}a_{ij} = (A^T)_i V_1 \nonumber \\
\text{tot}(d_i) &= \text{in}(d_i) + \text{out}(d_i) \sum_{i\neq j}a_{ji} + \sum_{i\neq j}a_{ij} = (A^T + A)_i V_1 \nonumber
\end{align}

When the edge is directed both ways, this degree is the summation of the products of all the edges of vertex $v$ that are bidirectional. Formally can be shown as equation \ref{eq:bd} with $A_{ii}$ as the i-th element of the diagonal for the matrix product of $A$.

\begin{equation} \label{eq:bd}
\text{bi}(d_i) = \sum_{i\neq j}a_{ij}a_{ji} = A_{ii}^2 \nonumber
\end{equation}
 
This equation is demonstrated by Fagio \cite{Fagiolo_2007} that measures the clustering coefficient for each vertex with directed edges with the consideration of the eight triangles that this vertex could form shown previously in figure \ref{fig:change}. 

So this equation can be demonstrated with vertex $i$ and pairs of neighbours $j$ and $k$ that essentially shows that the equation \ref{eq:dcc} calculates the triangles formed by $v$ over the possible triangles with the deduction of $2\text{bi}(d_i)$ as otherwise if vertex $i$ and $j$ had edges directed to each other, this causes a count of two addtional triangles.

\begin{align} \label{eq:dcc}
C_i &= \frac{\frac{1}{2}\sum_j \sum_k (a_{ij} + a_{ji})(a_{ik} + a_{ki})(a_{jk} + a_{kj})}{\text{tot}(d_i)(\text{tot}(d_i) - 1) - 2\text{bi}(d_i)} \\
&= \frac{(A + A^T)^3_{ii}}{2(\text{tot}(d_i)(\text{tot}(d_i) - 1) - 2\text{bi}(d_i))} = \frac{t_i}{T_i} \nonumber
\end{align}

Weights of the edges can be implemented into Fagio's equation of clustering coefficients by simple using a weighted adjacency matrix $W$ instead of the adjacency matrix $A$ for graph $G$. Mentioned before, the weights of the triangles can be considered differently however in Fagio's generalisation of the clustering coefficient equation, the mean weights of the triangles are utilised. This is shown by taking a cube root all elements of the weighted matrix $W$ which can be denoted as $W^{[1/3]}$. Therefore by subbing $W^{[\frac{1}{3}]}$ in the place of $A$ in equation \ref{eq:dcc}, the weighted directed version can be achieved, formally as equation \ref{eq:wdcc}.

\begin{equation} \label{eq:wdcc}
C_i = \frac{(W^{[\frac{1}{3}]} + (W^{[\frac{1}{3}]})^T)^3_{ii}}{2(\text{tot}(d_i)(\text{tot}(d_i) - 1) - 2\text{bi}(d_i))} = \frac{t_i}{T_i}
\end{equation}

However with this generalisation of the formula, it considers any triangle formed by a vertex $i$ as equal values. This means that the directions in the triangles are meaningless however due to the nature of directed graphs, their directions are what gives the graph it's flow of information and different directions will lead to different interpretations of the graph. Thus an improvement to properly include the directions of edges is to consider each motif separately or in Fagio's case, treat them by considering the 4 types of categories the motifs can fall under mentioned before in Figure \ref{fig:change}. 

These were cycles, middleman, fan-in and fan-out and by measuring each specific category then we can get more accurate coefficients for the relative pattern. The definition of number of all possible triangles was defined in equations \ref{eq:dcc} and \ref{eq:wdcc} as $T_i$. Similarly with the directed triangles that are actually formed by a vertex $i$ by $t_i$. These can be both decomposed into the 4 types of motifs which can then be used to create the clustering coefficient for each specific motif. Note that the sum of the clustering coefficient for specific motifs will be the general clustering coefficients for all triangles. The equations are decomposed as follows:

\begin{align}
T_i &= \text{tot}(d_i)(\text{tot}(d_i) - 1) - 2\text{bi}(d_i) \\
&= \text{in}(d_i)\text{out}(d_i) - \text{bi}(d_i) + \text{in}(d_i)\text{out}(d_i) - \text{bi}(d_i) \nonumber \\
&+ \text{in}(d_i)(\text{in}(d_i) - 1) + \text{out}(d_i)(\text{out}(d_i) - 1) \nonumber \\ 
&= \text{cyc}(T_1) + \text{mid}(T_2) + \text{fan-in}(T_3) + \text{fan-out}(T_4) \nonumber
\end{align}

\begin{align}
t_i &= (W^{[\frac{1}{3}]} + W^T)_{ii} \\
&= ({W^{[\frac{1}{3}]})}^3_{ii} + (W^{[\frac{1}{3}]}{W^{[\frac{1}{3}]}}^TW^{[\frac{1}{3}]})_{ii} + ({W^{[\frac{1}{3}]}}^T{W^{[\frac{1}{3}]}}^2)_{ii} + ({W^{[\frac{1}{3}]}}^2{W^{[\frac{1}{3}]}}^T)_{ii} \nonumber \\ 
&= \text{cyc}(t_1) + \text{mid}(t_2) + \text{fan-in}(t_3) + \text{fan-out}(t_4) \nonumber
\end{align}
 
So both equations can be split according to their different motifs through logical and algebraic reasoning. For $T_i$, the maximum number of directed triangles for cycles, middleman, fan-ins and fan-outs that can be formed equates to the total number of triangles for a vertex $i$. For example, when calculating cycles, the maximum number of directed cycles that can be formed with vertex $i$ is it's degree in multiplied by it's degree out, hence $\text{in}(d_i)\text{out}(d_i)$. However if a neighbour of i has an edge to and from the same vertex then this would account to an additional triangle counted hence the subtraction of the bidirectional edges by $- \text{bi}(d_i)$. Notice that middleman and cycles only differ according to the direction of the pairs of neighbours connected to vertex $i$ that forms the triangle hence the reason why $\text{cyc}(T_1) = \text{mid}(T_2)$. Then for the calculations of fan-in motif, it's the multiplications of the in degrees of $i$ and in degrees - 1 (as an edge is already considered) which gives the maximum fan-in motif styled triangles. Similarly for the fan-out motif.

Then for the actual triangles formed, they can be broken down by algebra shown by equation \ref{eq:cyca} which equates to the weighted matrix component seen in the original equation. Hence by algebraic manipulation, $t_i$ can be separated into the 4 motifs shown before.

\begin{align} \label{eq:cyca}
\text{cyc}(t_i) &= \frac{1}{2}\sum_j\sum_h{w_{ij}w_{jh}w_{hi} + w_{ih}w_{hj}w_{ji}} \\
&= \frac{1}{2}((W^{[\frac{1}{3}]})_{(i)}W^{[\frac{1}{3}]}(W^{[\frac{1}{3}]})^{(i)} + (W^{[\frac{1}{3}]})_{(i)}^T(W^{[\frac{1}{3}]})^T(W^{[\frac{1}{3}]})(W^{[\frac{1}{3}]})^{(i)}  \nonumber \\
&= (W^{[\frac{1}{3}]})_{(i)}W^{[\frac{1}{3}]}(W^{[\frac{1}{3}]})^{(i)} = ({W^{[\frac{1}{3}]})}^3_{ii} \nonumber \\ 
\end{align}

Finally, the clustering can be calculated according to the specific motifs of cycles, middleman, fan-in and fan out. Which can be formally defined as:

\begin{equation} \label{eq:wdmcc}
x(C_i) = \frac{x(t_i)}{x(T_i)}
\end{equation}

where $x$ = \{cyc, mid, fan-in, fan-out\} .\\

By demonstrating one specific formulation of the clustering coefficient applied to weighted directed graphs, we notice that depending on variations of properties in relation to the triangles, different values may occur for the same graph. Such properties include the various different motifs of the triangles and the consideration of the edge weights. This is what gave way to the multiple different versions as each has their benefit depending on what the graph represents which are thoroughly examined in the paper \cite{PhysRevResearch.3.043124}, all versions can also be analysed against each other to determine which has the best performance depending on the ideal requirements of the task\cite{CLEMENTE201826}.

\section{Centrality}
Positioning of the graph is a vital area in displaying and extracting important information whcih can then be assigned to the vertices and edges. The benefit of this is that it may be used to identfy key areas within a graph or network such as the the links between companies and which one has the most influence. This can also be applied to brain networs, the spreading patterns of disease and is useful to characterise sepcific areas to give a new interpretation of the graph. One of the major centrality value is the betweenness of vertices in a graph which will be describved in further detail in the next section.

\subsection{Betweeness centrality}
Betweenness centrality measures the centrality of a graph by using the shortest paths of pairs of vertices. The introduction of this idea was through the view of a comunications network. Where a point(or vertex) of the communicaitons network is deemed to be central if it lies on the shortest path between another pair of points in the network. Alex Bavelas\cite{bavelas1948mathematical} formulalised this idea of centrality where he suggests that a person in a group is in the central position if that person lies on the shortest path between other connecting pairs. With the immplication that this person then holds the power or responsibility for the others due to information exchange that must go through that point. A simplistic way of viewing the betweenness value for a vertex is that the larger the value, the greater number of shortest path connections it has to other vertices. In other words, if the value is large for a vertex, then the travel time from this vertex to other vertices is shorter. 

The betweenness centrality will be discussed based on Freeman's interpretation of betweenness centrality meaure\cite{freeman1977set}. For a simple unconnected and undirected graph $G = (V, E)$, consider all the unordered pairs of vertices $v_i, v_j \in V$ with $i \ne j$. This pair must either be disconnecter or has at least one path connecting them with it's path length based on the number of edges contained within. The path or paths connecting $v_i$ to $v_j$ with the shortest length is known to be the \emph{geodesics}. If the path is larger than one edge (the vertices were adjacent) then vertices in this geodesic are considered to be central. Depending if the vertex is the only central vertex between the pair of vertices determines whether it has complete or partial control of their link. The inutuion of control in betweenness was expressed by Shimbel\cite{shimbel1953structural} where work sites are considered as the vertices. Meaning that the vertices with control will be the connecting sites between other sites. Which in terms means that the connecting sites holds responsibility to the other sites and must relay information and resources to them. Figure \ref{fig:geodesics} expresses the idea of central vertices and the geodesics between them. Vertices $v_1$ and $v_3$ has two geodesics meaning that they share power. Also vertices $v_3$ and $v_6$ only has one geodesics through $v_4$ and $v_0$ so either $v_4$ or $v_0$ can have complete control.

\begin{figure}[!htb]
	\centering
	\includegraphics[width=.7\linewidth]{geod.png}
	\caption{A simple graph of six vetices and seven edges. Vertices $v_1$ and $v_3$ have two geodesics meaning that the central vertices are $v_4$ and $v_5$ who share partial control but $v_0$ has full control and is most central between $v_1$ and $v_3$. Note that $v_3$ and $v_6$ cannot be central as they only have one edge each and they only have one geodesics beacuse if $v_5$ or $v_1$ is included then it is no longer the shortest path between $v_3$ and $v_6$.}
	\label{fig:geodesics}
\end{figure}

To use the geodescides for a pair of vertices, if there are more than one geodescis then they are considered to have equal propability in deciding which one to be used. This is just simply given by $\frac{1}{g_{ij}}$ where $g_{ij}$ are the number of geodesics between vertices $v_i$ and $v_j$. The formulisation of partial betweenness $b_{ij}(v_k)$ is defined using the idea of geodesics, so for a vertex $v_k$ in $G$ and a vertex pair $v_i$ and $v_j$, the partial betweenness for $v_k$ can be calculated based on the vertex pair and is given by the equation

\begin{equation} \label{eq:gb}
b_{ij}(v_k) = \frac{1}{g_{ij}}(g_{ij}(v_k)) = \frac{g_{ij}(v_k)}{g_{ij}} (i \ne j \ne k)
\end{equation}

where $g_{ij}(v_k)$ is the amount of geodesics connecting vertices $v_i$ and $v_j$ that inlcude $v_k$ in it's path. This essentially translate to the probability that the geodesic chosen for $v_i$ and $v_j$ contains $v_k$. Additionaly, notice that $b_{ij}(v_k) = 0$ if there doesn't exist a path between the vertex pair, $v_i$ and $v_j$.
This can be extended to calculate the centrality of each vertex. So, for a graph of size $n$, the centrality value for a vertex $v_k \in V$ can be defined by

\begin{equation}
C_B(v_k)= \sum_i^n\sum_j^n b_{ij}(v_k)
\end{equation}
where $i < j$. So this defines the betweenness centrality for $v_k$ and it's value increases depending on the amount of geodesics that $v_k$ is a part of. The maximum value\cite{freeman2002centrality} was proved by Freeman through the use of a star with the central point as $v_k$ as all vertices are rachable through this central one. Furthermore, this means there are $n(n-1)/2$ paths between all the unordered pairs of the star graph $S$. With $n-1$ of these connected to the central vertex $v_k$. So the betweenness centrality for $S$ is

\begin{equation}
C_B(v_k)= \frac{n(n-1)}{2} - (n-1) = \frac{n^2-3n+2}{2}
\end{equation}

And if any new edge is added that doesnt increase the branches of the star, then a new geodesic would form without $v_k$ meaning that the value will fall. Therefore Equation \ref{eq:bcrmv} expresses the betweenness centrality of any vertex in a graph $G$ by it's represention though a ratio with the maximal value.

\begin{equation}\label{eq:bcrmv}
C'_B(v_k)= \frac{2C_B(v_k)}{n^2-3n+2}
\end{equation}

\subsection{Generlisation to directed graphs}
The key idea of betweenness centrality is to evaluate the graph and produce values according to the shortest paths of all the possible pairs of the graph. The higher the betweenness value, the more the vertex is likely to lie on the shortest paths of any two vertices. As this concept investigates the vertices and shortest paths, weighted edges wouldn't benefit this graph evaluation as weights could cause a pair of vertices to be seen as further apart than they actually are within the graph. In the experimentations of social networks\cite{freeman1979centrality}, the centrality values are used on undirected graphs however an idea to generlise the betweenness to weighted graphs is to take the weights as indication of the distance of the vertices. Meaning that the geodesics of any pair will be defined on the smallest total value of paths between them rather than the shortest path length as shown on Figure \ref{fig:dbc}.

\begin{figure}[!htb]
	\centering
	\includegraphics[width=.7\linewidth]{weightedbetween.png}
	\caption{a}
	\label{fig:dbc}
\end{figure}

Hence, we discuss the generalisation in this section only to directed graphs and if the graph has weights, then they are not implented to ensure betweenness values will not be influenced. The geodesic proportions of paths from $v_i$ and $v_j$ was defined earlier in Equation \ref{eq:gb}. Consequently, this eqation can be utilised to define pair-dependency of vertices $v_i$ to $v_k$ where the vertext $v_i$ has to depend on vertex $v_k$ in order to get to other vertices such as $v_j$ on it's geodesics. In other words, $v_k$ acts like a gatekeeper to $v_i$. Therefore, for a graph with $n$ vertices, the pair dependency is defined to be 

\begin{equation}\label{eq:bcrmv}
d^*_{ik} = \sum_{j=1}^{n}b_{ij}(v_k)
\end{equation}

where $i \ne j \ne k$. Matrices can be used to store the pair-depency values to provide an ease of use and is a better representation for all the values. The results can be arranged into the matrix $D$ defined as $D = (d^*_{ik})$. The elements of the matrix measures how much the vertex corresponding to the row number depends on vertex corresponding to the column number to be able to connect to other vertices in the graph. Additionally the betweenness centrality can also be calculated based on this matrix $D$ through the summation of the columns in which the sum will give the betweenness centrality for the column number that represents the vertex. Otherwise shown as

\begin{equation}
\sum_{i=1}^nd^*_{ik} = 2C_B(v_k)
\end{equation}

Which means that the betweenness centrality of $v_k$ is double of the pair dependency column sum\cite{white1994betweenness}. This is because for an undirected graph, the upper and lower diagonal matrix are equal due to the symmetry of graph $G$. The genereralisation for directed graph can then be shown to be

\begin{equation}
C_B(v_k) = \sum_{i=1}^nd^*_{ik}
\end{equation}

\subsection{Other centrality values}
Centrality in itself is a larger area within graph theory and other than the betweenness values, there are other similar atrributes such as the closeness centrality, eigenvalue centrality, Katz centrality\cite{katz1953new} and the Hyperlink-Induced Topic Search (HITS) centrality. All of which calculate values for the vertices or edges given their positions within the graph by various diffent methods. Interestingly the closeness centrality can be seen as the duality of betweenness centrality as they can be obtained from row and column summatiuons of the depency relation defined in the paper by Brandes, Borgatti and Freeman\cite{brandes2016maintaining}.
Betweenness studies the vertices that acts as bridghes between other geodesics whereas the closeness centraliuty measures the average distance of the shortest paths between any pairs of vertices. A vertex with high closeness value means that the distance to any other vertex is short on average. Closeness centrality\cite{brandes2007centrality} can simply be calculated as the inverse of total shortest distance from a vertex $i$ to all of vertices, demonstrated by equation \ref{eq:cce}.

\begin{equation}\label{eq:cce}
C_C(v_i) = \frac{1}{\sum_{j}^nd(v_i, v}
\end{equation}

where $i \ne j$. The calculation is for simply connected graphs however can be easily expanded to directed and weighted graphs by modying the calculation of the mesaure of distances for the graph in question. I.e. Take the total weights of the path length rather than the path length for weightedness and to consider only correct paths(travelling along an edge in the permiteed direction) when investigating directed graphs.

Therefore by taking these properties, the graph can be rearranged in accordance to their values. This is accomplished by having their property values as their position vector and is done so similarly in the paper by Juan, Alvarez, Villasante and Ruiz-Frau\cite{de2021graph} where they relabelled graphs with their normalised centrality values. This ranges from the betweenness centrality to eignevector centrality. Thus a similar idea can be applied along with the other properties explained and studied in this chapter.

\section{Webpages}
One of the largest graphs in the modern world is the network of web-pages, especially Google's search engine. To help navigate through the vast quantity of pages, Brin and Page\cite{brin1998anatomy} developed an algorithm known as the Page Rank algorithm. The Page rank gives a quantified meaning to the importance of the webpages and their links to other web-pages. Additionally the Page Rank is known as a centrality value which was discussed briefly in the last section along with the Hyperlink-Induced Topic Search (HITS) which was also created with a similar goal to Page Rank. Both these values are based upon digraphs (directed graphs) and was generated to help with the navigation of the world wide web and provide user's with the highest quality webpages that were also most relvant to their search criteria.

\subsection{Hyperlink-Induced Topic Search}
HITS calculate the ranks of \emph{authorities} and \emph{hubs} in relation to their in-links and out-links\cite{langville2005survey}, i.e. the edges pointing in and the edges going out of the vertices in the graph/network.  Authorities and Hubs are assigned to webpages(vertices) depending on their number of in-links and out-links. For the HITS algorithm, the webpages who has lots of in-links pointing to it are denoted as authorities and the webpages who has lots of out-links pointing to other webpages are denoted as the hubs. These can be identified through the use of the HITS algorithm as the calculations are an iterative process where it enforeces the authorities and hubs by bringing the authorities to the surface of the graph. Thus isolating them from other the other webpages. This is achieved by generating the hub and authority values by mutual reinforcement. Based on vertices $i \in V$ from a graph of webpages $G = (V , E)$, the hub value $h_i$ and authority value $a_i$ are first set to a value of 1. Then by Kleinberg's HITS algorithm, they are updates iteratively through the formulas:

\begin{equation}
a_i^(k) = \sum_{j:j->i \& j \ne i}h_j^{(k-1)} , \qquad \qquad h_i^(k) = \sum_{j:i \rightarrow j \& j \ne i}a_j^{(k)}
\end{equation}

where $j$ are denoted as the links from and to the webpages. The $k$ depicts the $k^{\text{th}}$ iteration of the algorithm, so the authority values depend on the previous iteration of hub values and the hubs are calculated based on the current authority values. Which gives the mutual reinforcement of both values. As the graph $G$ can be represented by an adjacency matrix $A = [a_{ij}]$, the formulas can be expressed through matrices\cite{chatzigeorgiou2006application} and vectors instead as:

\begin{equation}
\bold{a}^{(k)} = \bold{A}^{T}\bold{h}^{(k-1)} , \qquad \qquad \bold{h}^{(k)} = \bold{A}^{T}\bold{a}^{(k)}
\end{equation}

where the hub and authority values are adapted into vectors $\bold{a}^{(k)}$ and $\bold{h}^{(k)}$. The vectors are shown as

\begin{equation}
\bold{a}^{(k)} = \begin{bmatrix}
           a_1^{(k)} \\
           a_2^{(k)} \\
           \vdots \\
           a_n^{(k)}
         	\end{bmatrix}
           , \qquad \qquad 
\bold{h}^{(k)} = \begin{bmatrix}
           h_{1}^{(k)} \\
           h_{2}^{(k)} \\
           \vdots \\
           h_{n}^{(k)}
         	\end{bmatrix}
\end{equation}

Thus accomplishing the goals of generating the values which depict the hubs and authoritiies more clearly within the graph. Although this algorithm is currently defined only for directed weightless graphs so we extend the alrithm to include a weighted edge version.

\subsubsection{Normalisation and weights}
As the number of iterations increases, the values generated may increase. This means that at some point, the values will become too large to be used for any calculations so they can be normalised such that this doesnt occur. After $k$ iterations, the normalised formulas are demostrated by Equations (\ref{eq:nhits}) and the general outline for the HITs algorithm is demonstarted by Agosti and Pretto\cite{agosti2005theoretical} as the following:

\begin{algorithmic}
\State $\bold{a}^{(0)} := \bold{u}$ ,   $\bold{h}^{(0)} := \bold{u}$;
\For{$k := 1 \text{  to  } K$} 
   		 \State \qquad $\bold{a}^{(k)} = \bold{A}^{T}\bold{h}^{(k-1)}$;
		 \State \qquad $\bold{h}^{(k)} = \bold{A}^{T}\bold{a}^{(k)}$;
		 \State \qquad normalise $\bold{a}^{(k)}$ such that $\norm{\bold{a}^{(k)}} = 1$;
		 \State \qquad normalise $\bold{h}^{(k)}$ such that $\norm{\bold{h}^{(k)}} = 1$;
\EndFor 
\State $\bold{a} := \bold{a}^{(K)}$ ,   $\bold{h} := \bold{h}^{(K)}$;
\end{algorithmic}

where $K$ denotes the maximum number of iterations and $\bold{u}$ be the vector for the first iteration of hub and authority values, also known as the base case. The base case for $\bold{u}$ will just be the vector of ones known as $\bold{1}$ or $\bold{e}$ in linear algebra. So then the normalised values after $k$ iterations is given as follows:

\begin{equation} \label{eq:nhits}
\bold{a}^{(k)} = (\bold{A}^{T}\bold{A})^{k-1}\bold{A}^{T}\bold{u} , \qquad \qquad \bold{h}^{(k)} = (\bold{A}\bold{A}^{T})^{k}\bold{u}
\end{equation}

To incorporate weights of the edges into the algorithm, the weighted matrix $W$ for the graph $G$ can be used in place of the adjaceny matrix. Simply by replacing the $A$ in the formulas, the weighted version can be generated as the formulas:

\begin{equation} \label{eq:nhits}
\bold{a}^{(k)} = (\bold{W}^{T}\bold{W})^{k-1}\bold{W}^{T}\bold{u} , \qquad \qquad \bold{h}^{(k)} = (\bold{W}\bold{W}^{T})^{k}\bold{u}
\end{equation}

\subsection{Page Rank}
A widley known alorithm that contributes to the internet of navigation within Google is the Page Rank. The Page Ranks are needed because many different search query's can be entered onto the search engine to produce lots of results that contain the same or similar words to the search enquiry so a method to help organise or prioritise is necessary. The Page Rank is used to rank the web-pages according to the amount of backlinks a page may have and the number citations that reference a particular page. An example of a webpages and links as a graph is shown in Figure \ref{fig:page}.

\begin{figure}[!htb]
	\centering
	\includegraphics[width=.45\linewidth]{pagegraph.png}
	\caption{A graph representation of webpages and their in and out links. Algoithms such as Page Rank and HITS uses this graph format to help demonstrate their calculations. This image was sourced from the paper by Devi, Gupta and Dixit\cite{devi2014comparative} whom describes and compares Page Rank algorithm to the HITS algorithm.}
	\label{fig:page}
\end{figure}

For the graph $G = (V, E)$ the webpages can be seen as vertices$v \in V$ with their links as the edges directed edges between pages, the same way to how they were represented in the HITS formulas. We can let $F_v$ be the set of webpages that $v$ points to, i.e. the forward links. Similarly the backwards links as $B_v$ which is the set of webpages that points to $v$. The simpliefied version of Page Rank\cite{page1999pagerank} can then be defined with $N_v = \left|F_v\right|$ as the following:

\begin{equation}
PR(v) = c\sum_{w \in B_v}\frac{PR(w)}{N_w}
\end{equation}

where c is a variable used for normalisation pruposes so can be modified accordingly. So Page Rank is calculated by the even distribution of the Page Rank for webpage $v$ among webpages that $v$ points to. The values that links to other webpages from $v$ are then used to calculate their Page Rank. Hence giving an iterative approach to Page Rank as the algorithm travels along the links of the webpages. However if a webpage doesnt have outlinks and only inlinks from other webpages then their Page Rank is never distibuted to others causing it's valley to accumulate. This situation is known as a \emph{rank sink}.

A remedy to having a rank sink is to use a a damping factor to illustrate the probablilty that the user follows the links on the webpage. This takes into the consideration that users could skip pages or go directly to another webpage that wasn't linked throught the url. Hence ($1-d$) is considered as the distribution of the Page Rank from webpages that wasn't directly linked to it, i.e. no direct edges between them. Thus for the page $v$ with $b_i \in B_v$, the Page Rank\cite{brin1998anatomy} is defined through Equation \ref{eq:pr}.

\begin{equation} \label{eq:pr}
PR(v) = (1-d) + d (PR(b_1)/F(b_1) + … + PR(b_n)/F(b_n))
\end{equation}

where F(v) was retrieved from the set $F_v$ for webpage $v$. Page Rank is applied to each page and it is repeated on further pages until the equation converges. The damping factor adds randomness into the network of webpages so that the rank sink doesnt occur and ensures the convergence isn't reached too quickly. Usually the damping factor is taken to be 0.85. 

By using summation, the Page Rank formula can be simply reduced to

\begin{equation}
PR(v) = (1 - d) + d\sum_{w \in B_v}\frac{PR(w)}{N_w}
\end{equation}

\subsubsection{Personlisation}
The algorithm for Page Rank can be modified depending on the use and aims. Such modifications include adjusting the vertex and edge values, modifying the damping factor or to introduce a new variable into the algorithm. An example of a personlisation is the Weighted Page Rank\cite{xing2004weighted} where larger values are assigned to more popular/important webpages rather than the even distribution that occured beforehand. Webpages that are outlinked will instead recieve a value proportional to the pages popularity which are based off of their number of in links and out links. These popularity values of the in links and outlinks are represented as $W^{in}_{v,w}$ and $W^{out}_{v,w}$ accordingly. So $W^{in}_{v,w}$ is calculated by the inlinks of webpage $v$ shown to be $I_v$ and the inlinks of all the webpages that the webpage $w$ references, call this set of pages $R(w)$, as $I_p$ where $p \in R(w)$. This can then be formulased into the equation

\begin{equation}
W^{in}_{v,w} = \frac{I_v}{\sum_{p \in R(w)}}{I_p}
\end{equation}

Similarly, the same can be done for the outlinks 

\begin{equation}
W^{out}_{v,w} = \frac{O_v}{\sum_{p \in R(w)}}{O_p}
\end{equation}

Where $O_v$, $O_p$ is defined the same as the inlinks previously but with the use of the outlinks as replacement. Therefore, the Page Rank formula can be modified to include the webpages importance giving the formula

\begin{equation}
PR(v) = (1 - d) + d\sum_{w \in B_v}PR(w)W^{in}_{v,w}W^{out}_{v,w}
\end{equation}

So, this formula is focussed more upon the webpages that are visited more frequently by users and ensures they end up with a higher Page Rank. 

However, for the purpose of general directed weighted graphs, the edge weights are lost in the formula as the algorithm updates the Page Rank of every vertex in each iteration meaning that the weights can be disregarded and replaced with the Page Ranks instead. To ensure this doesn't happen, the weights of all the edges must be included in the ranks calculation. This is accomplished by summing up the weight values of the in and out edges and incorporating it into the formula as achieved by Equation \ref{eq:wpr}.

\begin{equation} \label{eq:wpr}
PR(v) = (1-d) + d\sum_{w \in B_v}\frac{PR(w)w_{(w \rightarrow v)}}{N_w}
\end{equation}

where $N_w = \sum_y{A_{w,y}w_(w -> y)}$ is redefined as the sum of weights of the out linked edges in relation to vertex $w$.
\\

Whilst HITs and Page Ranks are designed for the search engine, the network of web-pages essentially is a large directed graph that can contain weights hence why the Page Rank can be used on any derivatives of a weighted directed graph. Thus, there are additonal graphical property that can be used to help analyse the structure and linkage of a graph. 
